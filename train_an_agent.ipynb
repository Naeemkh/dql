{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game_controller import GameController\n",
    "from domain import Domain\n",
    "from util import create_random_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new random domain ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nkhshnvs/Dropbox/Naeem_Folder/Research_Project/F2019_009_deeplearning/experiment_014_20200903_dql/analysis/game_controller.py:157: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1595629444482/work/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  action = self.agent.choose_action(T.unsqueeze(T.tensor(observation, dtype=T.float32), dim=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep neural network is replaced.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nkhshnvs/Dropbox/Naeem_Folder/Research_Project/F2019_009_deeplearning/experiment_014_20200903_dql/analysis/models.py:128: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = T.tensor(x, dtype = T.float32)\n",
      "/Users/nkhshnvs/Dropbox/Naeem_Folder/Research_Project/F2019_009_deeplearning/experiment_014_20200903_dql/analysis/models.py:413: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1595629444482/work/aten/src/ATen/native/IndexingUtils.h:20.)\n",
      "  q_next[dones] = 0.0\n",
      "/Users/nkhshnvs/anaconda3/envs/pt36/lib/python3.6/site-packages/torch/autograd/__init__.py:127: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1595629444482/work/aten/src/ATen/native/IndexingUtils.h:20.)\n",
      "  allow_unreachable=True)  # allow_unreachable flag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated at:  371 --> True\n",
      "episode: 0, agent_loc: (7,1), epsilon: 0.9660000000000037, score: -73.54999999999947,(max: -73.54999999999947)\n",
      "episode: 1, agent_loc: (0,5), epsilon: 0.9160000000000093, score: -69.17499999999941,(max: -64.79999999999937)\n",
      "Deep neural network is replaced.\n",
      "Terminated at:  308 --> True\n",
      "episode: 2, agent_loc: (6,1), epsilon: 0.8852000000000126, score: -61.76666666666613,(max: -46.94999999999956)\n",
      "episode: 3, agent_loc: (9,6), epsilon: 0.8352000000000182, score: -63.924999999999436,(max: -46.94999999999956)\n",
      "Terminated at:  238 --> True\n",
      "episode: 4, agent_loc: (9,7), epsilon: 0.8114000000000208, score: -55.829999999999565,(max: -23.450000000000077)\n",
      "Deep neural network is replaced.\n",
      "episode: 5, agent_loc: (7,8), epsilon: 0.7614000000000263, score: -56.80833333333293,(max: -23.450000000000077)\n",
      "Terminated at:  447 --> True\n",
      "episode: 6, agent_loc: (5,7), epsilon: 0.7167000000000312, score: -56.5499999999996,(max: -23.450000000000077)\n",
      "Deep neural network is replaced.\n",
      "Terminated at:  239 --> True\n",
      "episode: 7, agent_loc: (9,8), epsilon: 0.6928000000000338, score: -53.274999999999665,(max: -23.450000000000077)\n",
      "Terminated at:  151 --> True\n",
      "episode: 8, agent_loc: (7,4), epsilon: 0.6777000000000355, score: -48.8888888888886,(max: -13.800000000000056)\n",
      "Terminated at:  327 --> True\n",
      "episode: 9, agent_loc: (4,7), epsilon: 0.6450000000000391, score: -47.58999999999975,(max: -13.800000000000056)\n",
      "Terminated at:  65 --> True\n",
      "episode: 10, agent_loc: (1,0), epsilon: 0.6385000000000398, score: -43.522727272727046,(max: -2.8499999999999943)\n",
      "Deep neural network is replaced.\n",
      "Terminated at:  496 --> True\n",
      "episode: 11, agent_loc: (2,3), epsilon: 0.5889000000000453, score: -44.34166666666642,(max: -2.8499999999999943)\n",
      "Terminated at:  114 --> True\n",
      "episode: 12, agent_loc: (6,1), epsilon: 0.5775000000000465, score: -41.36153846153824,(max: -2.8499999999999943)\n",
      "Terminated at:  238 --> True\n",
      "episode: 13, agent_loc: (1,7), epsilon: 0.5537000000000492, score: -39.374999999999794,(max: -2.8499999999999943)\n",
      "Terminated at:  197 --> True\n",
      "episode: 14, agent_loc: (9,2), epsilon: 0.5340000000000513, score: -38.116666666666475,(max: -2.8499999999999943)\n",
      "Terminated at:  148 --> True\n",
      "episode: 15, agent_loc: (6,1), epsilon: 0.519200000000053, score: -36.52812499999982,(max: -2.8499999999999943)\n",
      "Terminated at:  141 --> True\n",
      "episode: 16, agent_loc: (8,0), epsilon: 0.5051000000000545, score: -35.10588235294101,(max: -2.8499999999999943)\n",
      "Terminated at:  33 --> True\n",
      "episode: 17, agent_loc: (0,9), epsilon: 0.5018000000000549, score: -33.22499999999984,(max: -1.249999999999996)\n",
      "Deep neural network is replaced.\n",
      "Terminated at:  31 --> True\n",
      "episode: 18, agent_loc: (1,9), epsilon: 0.4987000000000552, score: -31.386842105263003,(max: 1.699999999999999)\n",
      "Terminated at:  77 --> True\n",
      "episode: 19, agent_loc: (7,6), epsilon: 0.49100000000005606, score: -29.86249999999985,(max: 1.699999999999999)\n",
      "Terminated at:  80 --> True\n",
      "episode: 20, agent_loc: (6,5), epsilon: 0.48300000000005694, score: -28.709523809523667,(max: 1.699999999999999)\n",
      "Terminated at:  85 --> True\n",
      "episode: 21, agent_loc: (7,1), epsilon: 0.4745000000000579, score: -27.579545454545322,(max: 1.699999999999999)\n",
      "Terminated at:  202 --> True\n",
      "episode: 22, agent_loc: (8,0), epsilon: 0.4543000000000601, score: -27.26956521739118,(max: 1.699999999999999)\n",
      "Terminated at:  222 --> True\n",
      "episode: 23, agent_loc: (6,7), epsilon: 0.43210000000006255, score: -26.783333333333218,(max: 1.699999999999999)\n",
      "Terminated at:  39 --> True\n",
      "episode: 24, agent_loc: (4,6), epsilon: 0.428200000000063, score: -25.73599999999989,(max: 1.699999999999999)\n",
      "Terminated at:  174 --> True\n",
      "episode: 25, agent_loc: (9,4), epsilon: 0.4108000000000649, score: -25.3749999999999,(max: 1.699999999999999)\n",
      "Deep neural network is replaced.\n",
      "Terminated at:  186 --> True\n",
      "episode: 26, agent_loc: (0,6), epsilon: 0.39220000000006694, score: -24.840740740740646,(max: 1.699999999999999)\n",
      "Terminated at:  61 --> True\n",
      "episode: 27, agent_loc: (8,5), epsilon: 0.3861000000000676, score: -23.946428571428477,(max: 1.699999999999999)\n",
      "Terminated at:  69 --> True\n",
      "episode: 28, agent_loc: (0,1), epsilon: 0.37920000000006837, score: -23.198275862068876,(max: 1.699999999999999)\n",
      "Terminated at:  29 --> True\n",
      "episode: 29, agent_loc: (2,3), epsilon: 0.3763000000000687, score: -22.333333333333247,(max: 2.749999999999999)\n",
      "Terminated at:  107 --> True\n",
      "episode: 30, agent_loc: (7,3), epsilon: 0.36560000000006987, score: -21.71129032258056,(max: 2.749999999999999)\n",
      "Terminated at:  101 --> True\n",
      "episode: 31, agent_loc: (1,3), epsilon: 0.355500000000071, score: -21.17812499999992,(max: 2.749999999999999)\n",
      "Terminated at:  38 --> True\n",
      "episode: 32, agent_loc: (6,5), epsilon: 0.3517000000000714, score: -20.553030303030223,(max: 2.749999999999999)\n",
      "Terminated at:  52 --> True\n",
      "episode: 33, agent_loc: (1,2), epsilon: 0.346500000000072, score: -19.957352941176392,(max: 2.749999999999999)\n",
      "Terminated at:  41 --> True\n",
      "episode: 34, agent_loc: (5,6), epsilon: 0.3424000000000724, score: -19.379999999999924,(max: 2.749999999999999)\n",
      "Terminated at:  36 --> True\n",
      "episode: 35, agent_loc: (8,9), epsilon: 0.3388000000000728, score: -18.85833333333326,(max: 2.749999999999999)\n",
      "Terminated at:  25 --> True\n",
      "episode: 36, agent_loc: (3,9), epsilon: 0.3363000000000731, score: -18.294594594594525,(max: 2.749999999999999)\n",
      "Terminated at:  29 --> True\n",
      "episode: 37, agent_loc: (4,6), epsilon: 0.3334000000000734, score: -17.76578947368414,(max: 2.749999999999999)\n",
      "Terminated at:  39 --> True\n",
      "episode: 38, agent_loc: (3,5), epsilon: 0.32950000000007384, score: -17.276923076923012,(max: 2.749999999999999)\n",
      "Terminated at:  56 --> True\n",
      "episode: 39, agent_loc: (2,6), epsilon: 0.32390000000007446, score: -16.833749999999934,(max: 2.749999999999999)\n",
      "Deep neural network is replaced.\n",
      "Terminated at:  327 --> True\n",
      "episode: 40, agent_loc: (9,0), epsilon: 0.29120000000007806, score: -17.03170731707311,(max: 2.749999999999999)\n",
      "Terminated at:  32 --> True\n",
      "episode: 41, agent_loc: (1,3), epsilon: 0.2880000000000784, score: -16.564285714285656,(max: 2.749999999999999)\n",
      "Terminated at:  32 --> True\n",
      "episode: 42, agent_loc: (2,5), epsilon: 0.28480000000007877, score: -16.229069767441803,(max: 2.749999999999999)\n",
      "Terminated at:  29 --> True\n",
      "episode: 43, agent_loc: (4,5), epsilon: 0.2819000000000791, score: -15.797727272727217,(max: 2.75)\n",
      "Terminated at:  48 --> True\n",
      "episode: 44, agent_loc: (5,6), epsilon: 0.2771000000000796, score: -15.448888888888835,(max: 2.75)\n",
      "Terminated at:  29 --> True\n",
      "episode: 45, agent_loc: (5,7), epsilon: 0.27420000000007994, score: -15.115217391304295,(max: 2.75)\n",
      "Terminated at:  56 --> True\n",
      "episode: 46, agent_loc: (5,5), epsilon: 0.26860000000008055, score: -14.888297872340376,(max: 2.75)\n",
      "Terminated at:  27 --> True\n",
      "episode: 47, agent_loc: (8,8), epsilon: 0.26590000000008085, score: -14.538541666666612,(max: 2.75)\n",
      "Terminated at:  36 --> True\n",
      "episode: 48, agent_loc: (9,9), epsilon: 0.26230000000008125, score: -14.234693877550967,(max: 2.75)\n",
      "Terminated at:  50 --> True\n",
      "episode: 49, agent_loc: (6,7), epsilon: 0.2573000000000818, score: -13.934999999999947,(max: 2.75)\n",
      "Terminated at:  23 --> True\n",
      "episode: 50, agent_loc: (6,8), epsilon: 0.25500000000008205, score: -13.620588235294067,(max: 2.75)\n",
      "Terminated at:  32 --> True\n",
      "episode: 51, agent_loc: (1,4), epsilon: 0.2518000000000824, score: -13.326923076923027,(max: 2.75)\n",
      "Terminated at:  64 --> True\n",
      "episode: 52, agent_loc: (8,9), epsilon: 0.2454000000000831, score: -13.128301886792404,(max: 2.75)\n",
      "Terminated at:  93 --> True\n",
      "episode: 53, agent_loc: (6,1), epsilon: 0.23610000000008413, score: -12.911111111111062,(max: 2.75)\n",
      "Terminated at:  39 --> True\n",
      "episode: 54, agent_loc: (5,2), epsilon: 0.23220000000008456, score: -12.635454545454497,(max: 2.75)\n",
      "Terminated at:  22 --> True\n",
      "episode: 55, agent_loc: (6,8), epsilon: 0.2300000000000848, score: -12.35446428571424,(max: 3.1)\n",
      "Terminated at:  29 --> True\n",
      "episode: 56, agent_loc: (0,9), epsilon: 0.22710000000008512, score: -12.106140350877148,(max: 3.1)\n",
      "Terminated at:  24 --> True\n",
      "episode: 57, agent_loc: (3,5), epsilon: 0.2247000000000854, score: -11.84568965517237,(max: 3.1)\n",
      "Terminated at:  37 --> True\n",
      "episode: 58, agent_loc: (1,2), epsilon: 0.2210000000000858, score: -11.60508474576267,(max: 3.1)\n",
      "Terminated at:  42 --> True\n",
      "episode: 59, agent_loc: (6,4), epsilon: 0.21680000000008626, score: -11.376666666666624,(max: 3.1)\n",
      "Terminated at:  53 --> True\n",
      "episode: 60, agent_loc: (2,4), epsilon: 0.21150000000008684, score: -11.180327868852416,(max: 3.1)\n",
      "Terminated at:  31 --> True\n",
      "episode: 61, agent_loc: (1,0), epsilon: 0.20840000000008718, score: -10.98790322580641,(max: 3.1)\n",
      "Terminated at:  27 --> True\n",
      "episode: 62, agent_loc: (5,8), epsilon: 0.20570000000008748, score: -10.798412698412656,(max: 3.1)\n",
      "Terminated at:  24 --> True\n",
      "episode: 63, agent_loc: (6,9), epsilon: 0.20330000000008774, score: -10.59999999999996,(max: 3.1)\n",
      "Terminated at:  23 --> True\n",
      "episode: 64, agent_loc: (4,7), epsilon: 0.201000000000088, score: -10.389999999999961,(max: 3.1)\n",
      "Deep neural network is replaced.\n",
      "Terminated at:  33 --> True\n",
      "episode: 65, agent_loc: (1,2), epsilon: 0.19770000000008836, score: -10.193939393939358,(max: 3.1)\n",
      "Terminated at:  32 --> True\n",
      "episode: 66, agent_loc: (8,6), epsilon: 0.1945000000000887, score: -10.01716417910444,(max: 3.1)\n",
      "Terminated at:  19 --> True\n",
      "episode: 67, agent_loc: (6,9), epsilon: 0.19260000000008892, score: -9.822058823529376,(max: 3.25)\n",
      "Terminated at:  26 --> True\n",
      "episode: 68, agent_loc: (9,2), epsilon: 0.1900000000000892, score: -9.637681159420255,(max: 3.25)\n",
      "Terminated at:  21 --> True\n",
      "episode: 69, agent_loc: (6,8), epsilon: 0.18790000000008944, score: -9.468571428571394,(max: 3.25)\n",
      "Terminated at:  29 --> True\n",
      "episode: 70, agent_loc: (3,5), epsilon: 0.18500000000008976, score: -9.309859154929544,(max: 3.25)\n",
      "Terminated at:  27 --> True\n",
      "episode: 71, agent_loc: (0,2), epsilon: 0.18230000000009006, score: -9.140972222222189,(max: 3.25)\n",
      "Terminated at:  21 --> True\n",
      "episode: 72, agent_loc: (7,1), epsilon: 0.1802000000000903, score: -8.972602739725994,(max: 3.25)\n",
      "Terminated at:  23 --> True\n",
      "episode: 73, agent_loc: (8,4), epsilon: 0.17790000000009054, score: -8.810135135135104,(max: 3.25)\n",
      "Terminated at:  22 --> True\n",
      "episode: 74, agent_loc: (9,1), epsilon: 0.17570000000009078, score: -8.66399999999997,(max: 3.25)\n",
      "Terminated at:  37 --> True\n",
      "episode: 75, agent_loc: (0,2), epsilon: 0.1720000000000912, score: -8.531578947368391,(max: 3.25)\n",
      "Terminated at:  36 --> True\n",
      "episode: 76, agent_loc: (5,0), epsilon: 0.1684000000000916, score: -8.414285714285684,(max: 3.25)\n",
      "Terminated at:  19 --> True\n",
      "episode: 77, agent_loc: (4,7), epsilon: 0.1665000000000918, score: -8.26474358974356,(max: 3.2500000000000004)\n",
      "Terminated at:  29 --> True\n",
      "episode: 78, agent_loc: (1,9), epsilon: 0.16360000000009212, score: -8.13734177215187,(max: 3.2500000000000004)\n",
      "Terminated at:  29 --> True\n",
      "episode: 79, agent_loc: (3,3), epsilon: 0.16070000000009244, score: -8.001249999999969,(max: 3.2500000000000004)\n",
      "Terminated at:  34 --> True\n",
      "episode: 80, agent_loc: (6,5), epsilon: 0.1573000000000928, score: -7.895061728395031,(max: 3.2500000000000004)\n",
      "Terminated at:  29 --> True\n",
      "episode: 81, agent_loc: (3,3), epsilon: 0.15440000000009313, score: -7.765243902438994,(max: 3.2500000000000004)\n",
      "Terminated at:  26 --> True\n",
      "episode: 82, agent_loc: (1,8), epsilon: 0.15180000000009342, score: -7.659638554216837,(max: 3.2500000000000004)\n",
      "Terminated at:  29 --> True\n",
      "episode: 83, agent_loc: (2,4), epsilon: 0.14890000000009374, score: -7.535714285714256,(max: 3.2500000000000004)\n",
      "Terminated at:  25 --> True\n",
      "episode: 84, agent_loc: (3,7), epsilon: 0.146400000000094, score: -7.423529411764677,(max: 3.2500000000000004)\n",
      "Terminated at:  19 --> True\n",
      "episode: 85, agent_loc: (0,9), epsilon: 0.14450000000009422, score: -7.299418604651134,(max: 3.2500000000000004)\n",
      "Terminated at:  29 --> True\n",
      "episode: 86, agent_loc: (2,0), epsilon: 0.14160000000009454, score: -7.183908045976983,(max: 3.2500000000000004)\n",
      "Terminated at:  26 --> True\n",
      "episode: 87, agent_loc: (4,5), epsilon: 0.13900000000009483, score: -7.090909090909062,(max: 3.2500000000000004)\n",
      "Terminated at:  21 --> True\n",
      "episode: 88, agent_loc: (3,9), epsilon: 0.13690000000009506, score: -6.977528089887612,(max: 3.2500000000000004)\n",
      "Terminated at:  26 --> True\n",
      "episode: 89, agent_loc: (6,7), epsilon: 0.13430000000009534, score: -6.86777777777775,(max: 3.2500000000000004)\n",
      "Terminated at:  29 --> True\n",
      "episode: 90, agent_loc: (5,7), epsilon: 0.13140000000009566, score: -6.772527472527446,(max: 3.2500000000000004)\n",
      "Terminated at:  25 --> True\n",
      "episode: 91, agent_loc: (3,5), epsilon: 0.12890000000009594, score: -6.666847826086929,(max: 3.2500000000000004)\n",
      "Terminated at:  22 --> True\n",
      "episode: 92, agent_loc: (8,1), epsilon: 0.12670000000009618, score: -6.56182795698922,(max: 3.2500000000000004)\n",
      "Terminated at:  22 --> True\n",
      "episode: 93, agent_loc: (6,1), epsilon: 0.12450000000009635, score: -6.459042553191463,(max: 3.2500000000000004)\n",
      "Terminated at:  19 --> True\n",
      "episode: 94, agent_loc: (5,7), epsilon: 0.1226000000000963, score: -6.356842105263131,(max: 3.2500000000000004)\n",
      "Terminated at:  26 --> True\n",
      "episode: 95, agent_loc: (9,7), epsilon: 0.12000000000009622, score: -6.270312499999974,(max: 3.2500000000000004)\n",
      "Terminated at:  22 --> True\n",
      "episode: 96, agent_loc: (4,8), epsilon: 0.11780000000009616, score: -6.18350515463915,(max: 3.2500000000000004)\n",
      "Terminated at:  22 --> True\n",
      "episode: 97, agent_loc: (6,7), epsilon: 0.1156000000000961, score: -6.088775510204057,(max: 3.2500000000000004)\n",
      "Terminated at:  30 --> True\n",
      "episode: 98, agent_loc: (3,0), epsilon: 0.11260000000009601, score: -6.020707070707046,(max: 3.2500000000000004)\n",
      "Terminated at:  23 --> True\n",
      "episode: 99, agent_loc: (2,8), epsilon: 0.11030000000009595, score: -5.929999999999976,(max: 3.2500000000000004)\n",
      "Terminated at:  19 --> True\n",
      "episode: 100, agent_loc: (4,8), epsilon: 0.10840000000009589, score: -5.839108910891065,(max: 3.2500000000000004)\n",
      "... saving checkpoint ...\n",
      "... saving checkpoint ...\n"
     ]
    }
   ],
   "source": [
    "domain_params = {'domain_shape':(10,10), \"num_wall\":4, \"num_gold\":2,\n",
    "                 'num_storage':2, \"use_available_domain\":False, \n",
    "                 'domain_type':\"2D\", \"new_agent_loc\":True,\n",
    "                 'domain_number':10061}\n",
    "\n",
    "ql_params = {'gamma':0.99, 'epsilon_max':1, \"epsilon_min\":0.01,\n",
    "             'epsilon_dec':0.0001, 'n_game': 500, 'stop_game_after': 500}\n",
    "\n",
    "dqn_params = {'mem_size':1000000, 'algorithm':\"DDQN\",'batch_size':32,\n",
    "              'learning_rate':0.0001 , 'load_pretrained_agent':False,\n",
    "              'start_from': 'domain_10_10_init_2',\n",
    "              'agent_number': 100234, 'replace_network_every':1000}\n",
    "\n",
    "\n",
    "output_folder = \"train_folder_1\"\n",
    "\n",
    "gc1 = GameController(domain_params, ql_params, dqn_params, output_folder=output_folder)\n",
    "gc1.train()\n",
    "gc1.domain.plot_domain(True)\n",
    "gc1.generate_animation_of_trained_model(random_agent_loc=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt36",
   "language": "python",
   "name": "pt36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
